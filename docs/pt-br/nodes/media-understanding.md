---
summary: "Inbound image/audio/video understanding (optional) with provider + CLI fallbacks"
read_when:
  - Designing or refactoring media understanding
  - Tuning inbound audio/video/image preprocessing
---

# Compreens√£o de m√≠dia (inbound) ‚Äî 2026-01-17

OpenClaw pode **summarize inbound media** (image/audio/video) antes que o pipeline de resposta seja executado. Ele detecta automaticamente quando ferramentas locais ou chaves de provedor est√£o dispon√≠veis, e pode ser desativado ou personalizado. Se o entendimento estiver desligado, os modelos ainda recebem os arquivos/URLs originais como de costume.

# # Objetivos

- Opcional: digerir pr√©-digerir m√≠dias de entrada em texto curto para roteamento mais r√°pido + melhor an√°lise de comando.
- Preservar a entrega de m√≠dia original para o modelo (sempre).
- Suporte ** APIs provedor** e **fallbacks CLI**.
- Permitir v√°rios modelos com backback ordenado (error/size/timeout).

# # Comportamento de alto n√≠vel

1. Recolha anexos (<<<CODE0>>, <<CODE1>>, <<CODE2>>>).
2. Para cada capacidade ativada (imagem/√°udio/v√≠deo), selecione anexos por pol√≠tica (padr√£o: **primeiro**).
3. Escolha a primeira entrada do modelo eleg√≠vel (tamanho + capacidade + autentica√ß√£o).
4. Se um modelo falhar ou a m√≠dia for muito grande, **regressa √† pr√≥xima entrada**.
5. Sobre o sucesso:
- <<CODE3>> torna-se <<CODE4>>, <<CODE5>>>, ou <<CODE6>>bloqueio.
- Conjuntos de √°udio <<CODE7>>; an√°lise de comandos usa texto de legenda quando presente,
Caso contr√°rio, a transcri√ß√£o.
- As legendas s√£o preservadas como <<CODE8>> dentro do bloco.

Se o entendimento falhar ou estiver desativado, **o fluxo de resposta continua** com o corpo original + anexos.

# # Vis√£o geral da configura√ß√£o

<<CODE0> suporta ** modelos compartilhados** mais sobreposi√ß√µes de capacidade:

- <<CODE0>>: lista de modelos partilhada (usar <<CODE1>> para porta).
- <<CODE2>>/ <<CODE3>>/ <<CODE4>:
- padr√µes (<<<CODE5>>, <<CODE6>>, <<CODE7>>, <<CODE8>>, <<CODE9>>)
- o fornecedor substitui (<<<CODE10>>, <<CODE11>>, <<CODE12>>)
- Op√ß√µes de √°udio Deepgram via <<CODE13>>
- lista opcional **percapabilidade <<CODE14>>** (preferidos antes de modelos partilhados)
- <<CODE15>> pol√≠tica (<<CODE16>>, <<CODE17>>, <<CODE18>>)
- <<CODE19>> (portagem opcional por canal/tipo de conversa√ß√£o/sess√£o)
- <<CODE20>>: m√°xima capacidade concorrente roda (padr√£o **2**).

```json5
{
  tools: {
    media: {
      models: [
        /* shared list */
      ],
      image: {
        /* optional overrides */
      },
      audio: {
        /* optional overrides */
      },
      video: {
        /* optional overrides */
      },
    },
  },
}
```

## # Modelo de entradas

Cada entrada <<CODE0> pode ser **fornecedor** ou **CLI**:

```json5
{
  type: "provider", // default if omitted
  provider: "openai",
  model: "gpt-5.2",
  prompt: "Describe the image in <= 500 chars.",
  maxChars: 500,
  maxBytes: 10485760,
  timeoutSeconds: 60,
  capabilities: ["image"], // optional, used for multi‚Äëmodal entries
  profile: "vision-profile",
  preferredProfile: "vision-fallback",
}
```

```json5
{
  type: "cli",
  command: "gemini",
  args: [
    "-m",
    "gemini-3-flash",
    "--allowed-tools",
    "read_file",
    "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
  ],
  maxChars: 500,
  maxBytes: 52428800,
  timeoutSeconds: 120,
  capabilities: ["video", "image"],
}
```

Os modelos CLI tamb√©m podem usar:

- <<CODE0>> (diret√≥rio que cont√©m o ficheiro multim√©dia)
- <<CODE1>> (direc√ß√£o de scratch criada para esta execu√ß√£o)
- <<CODE2>> (scratch arquivo caminho base, sem extens√£o)

# # Predefini√ß√µes e limites

Predefini√ß√£o recomendada:

- <<CODE0>: **500** para imagem/v√≠deo (curto, amig√°vel a comandos)
- <<CODE1>: **unset** para √°udio (transcri√ß√£o completa, a menos que voc√™ defina um limite)
- <<CODE2>>:
- imagem: **10MB**
- √°udio: **20MB**
- v√≠deo: **50MB**

Regras:

- Se a m√≠dia exceder <<CODE0>>, esse modelo √© ignorado e o **pr√≥ximo modelo √© tentado**.
- Se o modelo retornar mais do que <<CODE1>>, a sa√≠da √© aparada.
- <<CODE2> defaults to simple ‚ÄúDescreva o {media}.‚Äù mais a orienta√ß√£o <<CODE3> (imagem/v√≠deo somente).
- Se <<CODE4> mas nenhum modelo est√° configurado, OpenClaw tenta o
** modelo de resposta ativa** quando seu provedor suporta a capacidade.

## # Detectar automaticamente a compreens√£o da m√≠dia (por omiss√£o)

Se <<CODE0> n√£o estiver ** definido para <<CODE1>> e n√£o tiver
modelos configurados, OpenClaw detecta automaticamente nesta ordem e ** para no primeiro
op√ß√£o de trabalho**:

1. **CLIs locais** (audio somente; se instalado)
- <<CODE0> (necess√°rios <<CODE1>> com codificador/decodificador/juntar/pedras)
- <<CODE2>> (<<CODE3>>; usa <<CODE4>> ou o modelo min√∫sculo empacotado)
- <<CODE5>> (Python CLI; baixa modelos automaticamente)
2. ** Gemini CLI** (<<<CODE6>>>) utilizando <<CODE7>>
3. ** Chaves do fornecedor**
- √Åudio: OpenAI ‚Üí Groq ‚Üí Deepgram ‚Üí Google
- Imagem: OpenAI ‚Üí Antr√≥pico ‚Üí Google ‚Üí MiniMax
- V√≠deo: Google

Para desactivar a detec√ß√£o autom√°tica, definir:

```json5
{
  tools: {
    media: {
      audio: {
        enabled: false,
      },
    },
  },
}
```

Nota: A detec√ß√£o bin√°ria √© o melhor esfor√ßo em macOS/Linux/Windows; garanta que o CLI esteja em <<CODE0>> (expandimos <<CODE1>>), ou definimos um modelo CLI expl√≠cito com um caminho de comando completo.

# # Capacidades (opcional)

Se voc√™ definir <<CODE0>>, a entrada s√≥ ser√° executada para esses tipos de m√≠dia. Para compartilhado
listas, OpenClaw pode inferir padr√µes:

- <<CODE0>>, <<CODE1>>, <<CODE2>>: ** imagem**
- <<CODE3> (A API Gemini): **imagem + √°udio + v√≠deo**
- <<CODE4>: **audio**
- <<CODE5>: **audio**

Para as entradas CLI, **set <<CODE0>> explicitamente** para evitar coincid√™ncias.
Se omitir <<CODE1>>, a entrada √© eleg√≠vel para a lista em que aparece.

# # Matriz de suporte do provedor (integra√ß√µes OpenClaw)

Capacidade Integra√ß√£o do fornecedor Notas
‚ñ° ----------------------------------------------------------------------------------------------------------------------------------------------------------
‚ñ° Imagem ‚ñ° OpenAI / Anthropic / Google / others via <<CODE0> Qualquer modelo capaz de imagem no registro funciona. ‚ñ°
‚ñ° √Åudio ‚Ä¢ OpenAI, Groq, Deepgram, Google ‚Ä¢ Transcri√ß√£o do provedor (Whisper/Deepgram/Gemini).
V√≠deo do Google (A API Gemini)

# # Fornecedores recomendados

**Imagem**

- Prefere o seu modelo ativo se ele suporta imagens.
- Bons padr√µes: <<CODE0>>, <<CODE1>>, <<CODE2>>.

**Audio**

- <<CODE0>>, <<CODE1>>>, ou <<CODE2>>>.
- Retrocesso do CLI: <<CODE3> (whisper- cpp) ou <<CODE4>>.
- Configura√ß√£o do Deepgram: [Deepgram (tradu√ß√£o do √°udio)] (<<<LINK0>>>).

**V√≠deo**

- <<CODE0> (r√°pido), <<CODE1>> (mais rico).
- Retrocesso CLI: <<CODE2>> CLI (suporta <<CODE3>> em v√≠deo/√°udio).

# # Pol√≠tica de anexo

Controlos de capacidade <<CODE0>> que processam os anexos:

- <<CODE0>>: <<CODE1>> (padr√£o) ou <<CODE2>>
- <<CODE3>>: tampar o n√∫mero processado (padr√£o **1**)
- <<CODE4>>: <<CODE5>>, <<CODE6>>, <<CODE7>>, <<CODE8>

Quando <<CODE0>>, as sa√≠das s√£o marcadas <<CODE1>>, <<CODE2>>, etc.

# # Exemplos de configura√ß√£o

# # # 1) Lista de modelos compartilhados + sobreposi√ß√µes

```json5
{
  tools: {
    media: {
      models: [
        { provider: "openai", model: "gpt-5.2", capabilities: ["image"] },
        {
          provider: "google",
          model: "gemini-3-flash-preview",
          capabilities: ["image", "audio", "video"],
        },
        {
          type: "cli",
          command: "gemini",
          args: [
            "-m",
            "gemini-3-flash",
            "--allowed-tools",
            "read_file",
            "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
          ],
          capabilities: ["image", "video"],
        },
      ],
      audio: {
        attachments: { mode: "all", maxAttachments: 2 },
      },
      video: {
        maxChars: 500,
      },
    },
  },
}
```

### 2) √Åudio + V√≠deo apenas (imagem desligada)

```json5
{
  tools: {
    media: {
      audio: {
        enabled: true,
        models: [
          { provider: "openai", model: "gpt-4o-mini-transcribe" },
          {
            type: "cli",
            command: "whisper",
            args: ["--model", "base", "{{MediaPath}}"],
          },
        ],
      },
      video: {
        enabled: true,
        maxChars: 500,
        models: [
          { provider: "google", model: "gemini-3-flash-preview" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
            ],
          },
        ],
      },
    },
  },
}
```

# # # 3) compreens√£o opcional da imagem

```json5
{
  tools: {
    media: {
      image: {
        enabled: true,
        maxBytes: 10485760,
        maxChars: 500,
        models: [
          { provider: "openai", model: "gpt-5.2" },
          { provider: "anthropic", model: "claude-opus-4-5" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
            ],
          },
        ],
      },
    },
  },
}
```

# # # 4) Entrada √∫nica multimodal (capacidades expl√≠citas)

```json5
{
  tools: {
    media: {
      image: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
      audio: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
      video: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
    },
  },
}
```

# # Sa√≠da de status

Quando o entendimento da m√≠dia √© executado, <<CODE0>> inclui uma breve linha sum√°ria:

```
üìé Media: image ok (openai/gpt-5.2) ¬∑ audio skipped (maxBytes)
```

Isto mostra resultados de capacidade e o provedor/modelo escolhido quando aplic√°vel.

# # Notas

- Entender √© ** melhor-esfor√ßo**. Os erros n√£o bloqueiam as respostas.
- Os anexos ainda s√£o passados para modelos mesmo quando o entendimento √© desativado.
- Utilizar <<CODE0>> para limitar a compreens√£o (por exemplo, apenas DM).

# # Docs relacionados

- [Configura√ß√£o] (<<<<LINK0>>)
- [Suporte de Imagem e M√≠dia] (<<<LINK1>>>)
